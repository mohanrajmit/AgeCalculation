{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohanrajmit/AgeCalculation/blob/master/AgeEstimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYC378gUZeHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/mohanrajmit/AgeEstimation.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2mz-hmwZjBP",
        "colab_type": "text"
      },
      "source": [
        "Age Estimation for Indian Movie Face Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF9_5TY0asXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h27evF1PZiWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras imports\n",
        "\n",
        "from keras.applications.xception import Xception, preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.models import model_from_json\n",
        "from keras.layers import Input\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "\n",
        "# other imports\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "import h5py\n",
        "import os\n",
        "import json\n",
        "import datetime\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI9vFNfLaxOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(\"AgeCalculation/dataset/train/train.csv\")\n",
        "\n",
        "image_name = data[\"ID\"]\n",
        "label_name = data[\"Class\"]\n",
        "\n",
        "features = []\n",
        "labels = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpsQ-3XMayMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = Xception(weights=weights)\n",
        "model = Model(input=base_model.input, output=base_model.get_layer('avg_pool').output)\n",
        "image_size = (299, 299)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVkas67NdCzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path=\"AgeCalculation/dataset/train/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRjzEfGBbA1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image_name1,label in zip(image_name,label_name):\n",
        "\t\n",
        "\tprint(\"the image name  {} and label{}\" .format(image_name1,label))\n",
        "\timage_path= str(+image_name1)\n",
        "\t#print(image_path)\n",
        "\t#image =cv2.imread(image_path)\n",
        "\t#images.append(image)\n",
        "\t#labels.append(label)\n",
        "\n",
        "\timg = image.load_img(image_path, target_size=image_size)\n",
        "\tx = image.img_to_array(img)\n",
        "\tx = np.expand_dims(x, axis=0)\n",
        "\tx = preprocess_input(x)\n",
        "\tfeature = model.predict(x)\n",
        "\tflat = feature.flatten()\n",
        "\tfeatures.append(flat)\n",
        "\tlabels.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke7SugyKbCWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode the labels using LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le_labels = le.fit_transform(labels)\n",
        "\n",
        "# get the shape of training labels\n",
        "print (\"[STATUS] training labels: {}\".format(le_labels))\n",
        "print (\"[STATUS] training labels shape: {}\".format(le_labels.shape))\n",
        "\n",
        "# save features and labels\n",
        "h5f_data = h5py.File(\"features.h5\", 'w')\n",
        "h5f_data.create_dataset('dataset_1', data=np.array(features))\n",
        "\n",
        "h5f_label = h5py.File(\"label.h5\", 'w')\n",
        "h5f_label.create_dataset('dataset_1', data=np.array(le_labels))\n",
        "\n",
        "h5f_data.close()\n",
        "h5f_label.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8iPTeBjbPVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import h5py\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyXkEDcpbcvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(features),\n",
        "                                                                  np.array(labels),\n",
        "                                                                  test_size=test_size,\n",
        "                                                                  random_state=seed)\n",
        "\n",
        "print (\"[INFO] splitted train and test data...\")\n",
        "print (\"[INFO] train data  : {}\".format(trainData.shape))\n",
        "print (\"[INFO] test data   : {}\".format(testData.shape))\n",
        "print (\"[INFO] train labels: {}\".format(trainLabels.shape))\n",
        "print (\"[INFO] test labels : {}\".format(testLabels.shape))\n",
        "\n",
        "# use logistic regression as the model\n",
        "print (\"[INFO] creating model...\")\n",
        "model = LogisticRegression(random_state=seed)\n",
        "model.fit(trainData, trainLabels)\n",
        "\n",
        "# use rank-1 and rank-5 predictions\n",
        "print (\"[INFO] evaluating model...\")\n",
        "f = open(results, \"w\")\n",
        "rank_1 = 0\n",
        "rank_5 = 0\n",
        "\n",
        "# loop over test data\n",
        "for (label, features) in zip(testLabels, testData):\n",
        "\t# predict the probability of each class label and\n",
        "\t# take the top-5 class labels\n",
        "\tpredictions = model.predict_proba(np.atleast_2d(features))[0]\n",
        "\tpredictions = np.argsort(predictions)[::-1][:5]\n",
        "\n",
        "\t# rank-1 prediction increment\n",
        "\tif label == predictions[0]:\n",
        "\t\trank_1 += 1\n",
        "\n",
        "\t# rank-5 prediction increment\n",
        "\tif label in predictions:\n",
        "\t\trank_5 += 1\n",
        "\n",
        "# convert accuracies to percentages\n",
        "rank_1 = (rank_1 / float(len(testLabels))) * 100\n",
        "rank_5 = (rank_5 / float(len(testLabels))) * 100\n",
        "\n",
        "# write the accuracies to file\n",
        "f.write(\"Rank-1: {:.2f}%\\n\".format(rank_1))\n",
        "f.write(\"Rank-5: {:.2f}%\\n\\n\".format(rank_5))\n",
        "\n",
        "# evaluate the model of test data\n",
        "preds = model.predict(testData)\n",
        "\n",
        "# write the classification report to file\n",
        "f.write(\"{}\\n\".format(classification_report(testLabels, preds)))\n",
        "f.close()\n",
        "\n",
        "# dump classifier to file\n",
        "print (\"[INFO] saving model...\")\n",
        "pickle.dump(model, open(classifier_path, 'wb'))\n",
        "\n",
        "# display the confusion matrix\n",
        "print (\"[INFO] confusion matrix\")\n",
        "\n",
        "# get the list of training lables\n",
        "labels = sorted(list(os.listdir(train_path)))\n",
        "\n",
        "# plot the confusion matrix\n",
        "cm = confusion_matrix(testLabels, preds)\n",
        "sns.heatmap(cm,\n",
        "            annot=True,\n",
        "            cmap=\"Set2\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}